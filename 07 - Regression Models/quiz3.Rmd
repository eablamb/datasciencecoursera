---
title: 'Regression Models: Quiz #3'
author: "Eugene Lamb"
date: "Saturday, April 25, 2015"
output: html_document
---

```{r, echo=FALSE}
options(scipen=999)
```

## Question 1

Consider the `mtcars` data set. Fit a model with mpg as the outcome that includes number of cylinders as a factor variable and weight as confounder. Give the adjusted estimate for the expected change in mpg comparing 8 cylinders to 4.

Answer:

```{r}
data(mtcars)
fit <- lm(mpg ~ factor(cyl) + wt, data = mtcars)
ans <- coef(fit)[3]
round(ans, 3)
```

## Question 2

Consider the `mtcars` data set. Fit a model with mpg as the outcome that includes number of cylinders as a factor variable and weight as a possible confounding variable. Compare the effect of 8 versus 4 cylinders on mpg for the adjusted and unadjusted by weight models. Here, adjusted means including the weight variable as a term in the regression model and unadjusted means the model without weight included. What can be said about the effect comparing 8 and 4 cylinders after looking at models with and without weight included?.

Answer:

```{r}
fit.unadj <- lm(mpg ~ factor(cyl), data = mtcars)
cf.unadj <- coef(fit.unadj)[3]

fit.adj <- lm(mpg ~ factor(cyl) + wt, data = mtcars)
cf.adj <- coef(fit.adj)[3]
```

Looking at the unadjusted coefficients, we see that the effect of an 8-cylinder engine on MPG is `r round(cf.unadj, 3)`.  
After adjusting for weight the effect is `r round(cf.adj, 3)`.  

**Holding weight constant, cylinder appears to have less of an impact on MPG than if weight is disregarded.**

## Question 3

Consider the mtcars data set. Fit a model with mpg as the outcome that considers number of cylinders as a factor variable and weight as confounder. Now fit a second model with mpg as the outcome model that considers the interaction between number of cylinders (as a factor variable) and weight. Give the P-value for the likelihood ratio test comparing the two models and suggest a model using 0.05 as a type I error rate significance benchmark. 

Answer:

```{r}
fit.a <- lm(mpg ~ factor(cyl) + wt, data = mtcars)
fit.b <- lm(mpg ~ factor(cyl) * wt, data = mtcars)     

cmp <- anova(fit.a, fit.b)
p.val <- cmp[['Pr(>F)']][2]
p.val
```

**The P-value is larger than 0.05.  So, according to our criterion, we would fail to reject, which suggests that the interaction terms may not be necessary.**

## Question 4

Consider the mtcars data set. Fit a model with mpg as the outcome that includes number of cylinders as a factor variable and weight inlcuded in the model as

```{r}
fit <- lm(mpg ~ I(wt * 0.5) + factor(cyl), data = mtcars)
```

How is the wt coefficient interpretted?

Answer:

**The estimated expected change in MPG per one ton increase in weight for a specific number of cylinders (4, 6, 8).**

## Question 5

Consider the following data set

```{r}
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
```

Give the hat diagonal for the most influential point

Answer:

First, let's fit the regression line and visualize it along with the data points.

```{r}
fit <- lm(y ~ x)

plot(x,y)
abline(coef(fit)[1], coef(fit)[2], lwd = 3)
```

Just based on looking at the data, it looks like if we remove the 5th point, then our predictions would change drastically.
Let's confirm this intuition with a series of tests.

Let's check the hat values.  These values will be between 0 and 1, and larger values indicate greater leverage.

```{r}
hat.vals <- hatvalues(fit)
hat.vals
```

It looks like the 5th point has the greatest leverage.  Let's see if it's also the most influential.

```{r}
# Change in predicted response when the ith point is deleted in fitting the model
dffits(fit)
```

```{r}
# Change in individual coefficients when the ith point is deleted in fitting the model
dfbetas(fit)
```

```{r}
# Overall change in coefficients when the ith point is deleted in fitting the model
cooks.distance(fit)
```

All these measures confirm that the 5th point is the most influential.  The hat value for this point is **`r round(hat.vals[[5]], 4)`**.

## Question 6

Consider the following data set

```{r}
x <- c(0.586, 0.166, -0.042, -0.614, 11.72)
y <- c(0.549, -0.026, -0.127, -0.751, 1.344)
```

Give the slope dfbeta for the point with the highest hat value.

Answer:

```{r}
round(dfbetas(fit)[5,2], 0)
```
 
## Question 7

Consider a regression relationship between Y and X with and without adjustment for a third variable Z. Which of the following is true about comparing the regression coefficient between Y and X with and without adjustment for Z.

Answer:

**It is possible for the coefficient to reverse sign after adjustment.  For example, it can be strongly significant and positive before adjustment and strongly significant and negative after adjustment.**